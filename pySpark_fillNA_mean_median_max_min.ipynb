{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pySpark NA_fill_custom_function.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75hs61WaFp9L",
        "colab_type": "text"
      },
      "source": [
        "# Spark in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEZICZsbX9gY",
        "colab_type": "code",
        "outputId": "c1eaa0a4-5a48-4be8-fb9b-55f5564c8a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "!apt-get update\n",
        "!wget --no-check-certificate https://archive.apache.org/dist/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz -O spark-2.2.1-bin-hadoop2.7.tar.gz\n",
        "!gunzip spark-2.2.1-bin-hadoop2.7.tar.gz\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!tar xf spark-2.2.1-bin-hadoop2.7.tar\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [2 InRelease 0 B/3,626 B 0%] [Wa\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.175)] [4 InRelease 2,567 B/88.7\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.175)\r                                                                               \rHit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.175)\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.175)\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.175)\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.175)\r                                                                               \rGet:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [9 InRelease 14.2 kB/88.7 kB 16%] [4 InRelease 46\r                                                                               \rGet:10 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [70.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,678 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [4,957 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,283 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [765 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [7,802 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [938 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [640 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [8,000 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [18.5 kB]\n",
            "Get:24 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [807 kB]\n",
            "Fetched 6,491 kB in 21s (306 kB/s)\n",
            "Reading package lists... Done\n",
            "--2019-09-04 10:10:53--  https://archive.apache.org/dist/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 163.172.17.199\n",
            "Connecting to archive.apache.org (archive.apache.org)|163.172.17.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200934340 (192M) [application/x-gzip]\n",
            "Saving to: ‘spark-2.2.1-bin-hadoop2.7.tar.gz’\n",
            "\n",
            "spark-2.2.1-bin-had 100%[===================>] 191.62M  28.8MB/s    in 7.3s    \n",
            "\n",
            "2019-09-04 10:11:01 (26.3 MB/s) - ‘spark-2.2.1-bin-hadoop2.7.tar.gz’ saved [200934340/200934340]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee97y0N5Fp9M",
        "colab_type": "text"
      },
      "source": [
        "## Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaiEK5xRV_G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.2.1-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQep9nK_Fp9O",
        "colab_type": "code",
        "outputId": "41035be0-cfbf-4065-f696-f9a16b29bc96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.2.1-bin-hadoop2.7\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import random\n",
        "import re\n",
        "!pip install findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import date, datetime\n",
        "from collections import Counter\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import lit, col, when\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import StringType, DoubleType, IntegerType, ArrayType, DateType\n",
        "\n",
        "from pyspark.mllib.stat import Statistics\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml.stat import Correlation, ChiSquareTest\n",
        "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.6/dist-packages (1.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0rhM5DYFp9V",
        "colab_type": "text"
      },
      "source": [
        "## Loading data to design new functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eamZwLkWFp9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATAPATH = os.path.join('content', 'drive', 'My Drive', 'Data') \n",
        "ruta_datos = \"/\" + DATAPATH + \"/bank_uci/bank-full.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3wyduRaXEKz",
        "colab_type": "code",
        "outputId": "6edfc01d-2301-4ba8-ac31-89117b817e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "auto = spark.read.csv(ruta_datos, sep=';', header=True, inferSchema=True)\n",
        "auto.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "| 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|\n",
            "| 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|\n",
            "| 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|\n",
            "| 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|\n",
            "| 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|\n",
            "| 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown| no|\n",
            "| 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown| no|\n",
            "| 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown| no|\n",
            "| 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown| no|\n",
            "| 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown| no|\n",
            "| 41|      admin.|divorced|secondary|     no|    270|    yes|  no|unknown|  5|  may|     222|       1|   -1|       0| unknown| no|\n",
            "| 29|      admin.|  single|secondary|     no|    390|    yes|  no|unknown|  5|  may|     137|       1|   -1|       0| unknown| no|\n",
            "| 53|  technician| married|secondary|     no|      6|    yes|  no|unknown|  5|  may|     517|       1|   -1|       0| unknown| no|\n",
            "| 58|  technician| married|  unknown|     no|     71|    yes|  no|unknown|  5|  may|      71|       1|   -1|       0| unknown| no|\n",
            "| 57|    services| married|secondary|     no|    162|    yes|  no|unknown|  5|  may|     174|       1|   -1|       0| unknown| no|\n",
            "| 51|     retired| married|  primary|     no|    229|    yes|  no|unknown|  5|  may|     353|       1|   -1|       0| unknown| no|\n",
            "| 45|      admin.|  single|  unknown|     no|     13|    yes|  no|unknown|  5|  may|      98|       1|   -1|       0| unknown| no|\n",
            "| 57| blue-collar| married|  primary|     no|     52|    yes|  no|unknown|  5|  may|      38|       1|   -1|       0| unknown| no|\n",
            "| 60|     retired| married|  primary|     no|     60|    yes|  no|unknown|  5|  may|     219|       1|   -1|       0| unknown| no|\n",
            "| 33|    services| married|secondary|     no|      0|    yes|  no|unknown|  5|  may|      54|       1|   -1|       0| unknown| no|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6vDhF9tima",
        "colab_type": "code",
        "outputId": "26fb5d38-602a-4033-aad2-6ad199b4d937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from random import randint\n",
        "\n",
        "auto = auto.withColumn(\"nulltest\", lit(None).cast(StringType()))\n",
        "auto = auto.withColumn(\"nulltest\", when(\n",
        "        col(\"job\") == \"management\",\n",
        "        1\n",
        "    ).otherwise(col(\"nulltest\")))\n",
        "auto = auto.withColumn(\"nulltest\", when(\n",
        "        col(\"job\") == \"technician\",\n",
        "        2\n",
        "    ).otherwise(col(\"nulltest\")))\n",
        "auto = auto.withColumn(\"nulltest\", when(\n",
        "        col(\"job\") == \"entrepreneur\",\n",
        "        3\n",
        "    ).otherwise(col(\"nulltest\")))\n",
        "auto.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+--------+\n",
            "|age|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|nulltest|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+--------+\n",
            "| 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|       1|\n",
            "| 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|       2|\n",
            "| 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|       3|\n",
            "| 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|    null|\n",
            "| 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|    null|\n",
            "| 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown| no|       1|\n",
            "| 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown| no|       1|\n",
            "| 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown| no|       3|\n",
            "| 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown| no|    null|\n",
            "| 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown| no|       2|\n",
            "| 41|      admin.|divorced|secondary|     no|    270|    yes|  no|unknown|  5|  may|     222|       1|   -1|       0| unknown| no|    null|\n",
            "| 29|      admin.|  single|secondary|     no|    390|    yes|  no|unknown|  5|  may|     137|       1|   -1|       0| unknown| no|    null|\n",
            "| 53|  technician| married|secondary|     no|      6|    yes|  no|unknown|  5|  may|     517|       1|   -1|       0| unknown| no|       2|\n",
            "| 58|  technician| married|  unknown|     no|     71|    yes|  no|unknown|  5|  may|      71|       1|   -1|       0| unknown| no|       2|\n",
            "| 57|    services| married|secondary|     no|    162|    yes|  no|unknown|  5|  may|     174|       1|   -1|       0| unknown| no|    null|\n",
            "| 51|     retired| married|  primary|     no|    229|    yes|  no|unknown|  5|  may|     353|       1|   -1|       0| unknown| no|    null|\n",
            "| 45|      admin.|  single|  unknown|     no|     13|    yes|  no|unknown|  5|  may|      98|       1|   -1|       0| unknown| no|    null|\n",
            "| 57| blue-collar| married|  primary|     no|     52|    yes|  no|unknown|  5|  may|      38|       1|   -1|       0| unknown| no|    null|\n",
            "| 60|     retired| married|  primary|     no|     60|    yes|  no|unknown|  5|  may|     219|       1|   -1|       0| unknown| no|    null|\n",
            "| 33|    services| married|secondary|     no|      0|    yes|  no|unknown|  5|  may|      54|       1|   -1|       0| unknown| no|    null|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkq4buWj0itS",
        "colab_type": "code",
        "outputId": "989dd9b0-b80c-4e23-b2ba-dbb0e492f5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "## Custom made function to fill NAs with mean, minimum, maximum or median for a given set of columns\n",
        "\n",
        "from pyspark.sql import DataFrameStatFunctions as stat\n",
        "\n",
        "def multiple_fill_na(df, include=set(), method=set()): \n",
        "      valid = {\"mean\" , \"minimum\", \"maximum\", \"median\"}\n",
        "      if method not in valid:\n",
        "          raise ValueError(\"results: status must be one of %r.\" % valid)\n",
        "      elif method == \"mean\":\n",
        "        #compute the mean of the given column(s) and store it.\n",
        "        stats = df.agg(*(\n",
        "          F.mean(c).alias(c) for c in df.columns if c in include\n",
        "        ))\n",
        "        dicti = stats.first().asDict()\n",
        "\n",
        "      elif method == \"minimum\":\n",
        "        #compute the minimum of the given column(s) and store it.\n",
        "        stats = df.agg(*(\n",
        "          F.min(c).alias(c) for c in df.columns if c in include\n",
        "        ))\n",
        "        dicti = stats.first().asDict()\n",
        "\n",
        "      elif method == \"maximum\":\n",
        "        #compute the maximum of the given column(s) and store it.\n",
        "        stats = df.agg(*(\n",
        "          F.max(c).alias(c) for c in df.columns if c in include\n",
        "        ))\n",
        "        dicti = stats.first().asDict()\n",
        "      elif method == \"median\":\n",
        "          ## filter numeric cols\n",
        "          num_cols = [col_type[0] for col_type in filter(lambda dtype: dtype[1] in {\"bigint\", \"double\", \"int\"}, \n",
        "          df.dtypes)]\n",
        "          ### Compute a dict with <col_name, median_value>\n",
        "          dicti = dict()\n",
        "          for c in num_cols:\n",
        "            dicti[c] = df.stat.approxQuantile(c, [0.5], 0.001)[0] \n",
        "      return df.na.fill(dicti)\n",
        "\n",
        "\n",
        "auto_modified = multiple_fill_na(auto, \"nulltest\", \"mean\")\n",
        "auto_modified.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+------------------+\n",
            "|age|         job| marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|          nulltest|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+------------------+\n",
            "| 58|  management| married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown| no|                 1|\n",
            "| 44|  technician|  single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown| no|                 2|\n",
            "| 33|entrepreneur| married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown| no|                 3|\n",
            "| 47| blue-collar| married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 33|     unknown|  single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 35|  management| married| tertiary|     no|    231|    yes|  no|unknown|  5|  may|     139|       1|   -1|       0| unknown| no|                 1|\n",
            "| 28|  management|  single| tertiary|     no|    447|    yes| yes|unknown|  5|  may|     217|       1|   -1|       0| unknown| no|                 1|\n",
            "| 42|entrepreneur|divorced| tertiary|    yes|      2|    yes|  no|unknown|  5|  may|     380|       1|   -1|       0| unknown| no|                 3|\n",
            "| 58|     retired| married|  primary|     no|    121|    yes|  no|unknown|  5|  may|      50|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 43|  technician|  single|secondary|     no|    593|    yes|  no|unknown|  5|  may|      55|       1|   -1|       0| unknown| no|                 2|\n",
            "| 41|      admin.|divorced|secondary|     no|    270|    yes|  no|unknown|  5|  may|     222|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 29|      admin.|  single|secondary|     no|    390|    yes|  no|unknown|  5|  may|     137|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 53|  technician| married|secondary|     no|      6|    yes|  no|unknown|  5|  may|     517|       1|   -1|       0| unknown| no|                 2|\n",
            "| 58|  technician| married|  unknown|     no|     71|    yes|  no|unknown|  5|  may|      71|       1|   -1|       0| unknown| no|                 2|\n",
            "| 57|    services| married|secondary|     no|    162|    yes|  no|unknown|  5|  may|     174|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 51|     retired| married|  primary|     no|    229|    yes|  no|unknown|  5|  may|     353|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 45|      admin.|  single|  unknown|     no|     13|    yes|  no|unknown|  5|  may|      98|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 57| blue-collar| married|  primary|     no|     52|    yes|  no|unknown|  5|  may|      38|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 60|     retired| married|  primary|     no|     60|    yes|  no|unknown|  5|  may|     219|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "| 33|    services| married|secondary|     no|      0|    yes|  no|unknown|  5|  may|      54|       1|   -1|       0| unknown| no|1.5701110991263079|\n",
            "+---+------------+--------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLbXGOd7wtpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fill_values = {column: df_data.agg({column:\"mean\"}).flatMap(list)[0] for column in df_data.columns if column not in ['date','id']}\n",
        "df_data = df_data.na.fill(fill_values)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}